{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "39a9b81d",
            "metadata": {"lines_to_next_cell": 1},
            "outputs": [],
            "source": [
                "import json\n",
                "import os\n",
                "from datasets import load_dataset, load_metric\n",
                "from transformers import PreTrainedTokenizerFast, BartTokenizerFast\n",
                "from transformers import BartConfig, BartModel, BartForConditionalGeneration\n",
                "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
                "from transformers import DataCollatorForSeq2Seq\n",
                "import torch\n",
                "import numpy as np\n",
                "import yaml\n",
                "import argparse",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "419629ae-5eb1-4369-9205-6c7496b60e00",
            "metadata": {},
            "outputs": [],
            "source": ['os.environ["CUDA_VISIBLE_DEVICES"]="2"'],
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "6b222b15-7db4-4bdd-b5f0-efc11b779669",
            "metadata": {},
            "outputs": [],
            "source": [
                'config_path = "pretrained_bart_config.yaml"\n',
                "with open(config_path) as f:\n",
                "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "8d381cb2",
            "metadata": {"lines_to_next_cell": 2},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Using custom data configuration default-f4cee673dc41c6a4\n",
                        "Reusing dataset json (/ldap_home/aurelio.prahara/.cache/huggingface/datasets/json/default-f4cee673dc41c6a4/0.0.0/793d004298099bd3c4e61eb7878475bcf1dc212bf2e34437d85126758720d7f9)\n",
                        "Loading cached processed dataset at /ldap_home/aurelio.prahara/.cache/huggingface/datasets/json/default-f4cee673dc41c6a4/0.0.0/793d004298099bd3c4e61eb7878475bcf1dc212bf2e34437d85126758720d7f9/cache-dfc29295cac14151.arrow\n",
                        "Loading cached processed dataset at /ldap_home/aurelio.prahara/.cache/huggingface/datasets/json/default-f4cee673dc41c6a4/0.0.0/793d004298099bd3c4e61eb7878475bcf1dc212bf2e34437d85126758720d7f9/cache-eb3106112c22c68f.arrow\n",
                        "Using amp fp16 backend\n",
                    ],
                }
            ],
            "source": [
                "\n",
                "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "\n",
                "    raw_datasets = load_dataset('json', data_files ={'train': config['train_data_dir'], 'valid': config['valid_data_dir']}, field='data')\n",
                "    metric = load_metric(config['metric'])\n",
                "\n",
                "    en_tokenizer = PreTrainedTokenizerFast(tokenizer_file=config['source_tokenizer'])\n",
                "    id_tokenizer = PreTrainedTokenizerFast(tokenizer_file=config['target_tokenizer'])\n",
                "    en_tokenizer.unk_token,en_tokenizer.cls_token, en_tokenizer.sep_token,en_tokenizer.pad_token, en_tokenizer.mask_token = ['[UNK]', '[CLS]', '[SEP]', '[PAD]', '[MASK]']\n",
                "    id_tokenizer.unk_token, id_tokenizer.cls_token, id_tokenizer.sep_token, id_tokenizer.pad_token, id_tokenizer.mask_token = ['[UNK]', '[CLS]', '[SEP]', '[PAD]', '[MASK]']\n",
                "\n",
                "    encoder_max_length = config['encoder_max_length']\n",
                "    decoder_max_length = config['decoder_max_length']\n",
                "    source_lang = config['source_lang']\n",
                "    target_lang = config['target_lang']\n",
                "\n",
                "    def process_data_to_model_inputs(batch):\n",
                "      # tokenize the inputs and labels\n",
                '      inputs = [ex[source_lang] for ex in batch["translation"]]\n',
                '      targets = [ex[target_lang] for ex in batch["translation"]]\n',
                '      inputs = en_tokenizer(inputs, padding="max_length", truncation=True, max_length=encoder_max_length)\n',
                '      outputs = id_tokenizer(targets, padding="max_length", truncation=True, max_length=decoder_max_length)\n',
                "\n",
                '      batch["input_ids"] = inputs.input_ids\n',
                '      batch["attention_mask"] = inputs.attention_mask\n',
                '      batch["decoder_input_ids"] = outputs.input_ids\n',
                '      batch["decoder_attention_mask"] = outputs.attention_mask\n',
                '      batch["labels"] = outputs.input_ids.copy()\n',
                "\n",
                "      # because BERT automatically shifts the labels, the labels correspond exactly to `decoder_input_ids`. \n",
                "      # We have to make sure that the PAD token is ignored\n",
                '      batch["labels"] = [[-100 if token == en_tokenizer.pad_token_id else token for token in labels] for labels in batch["labels"]]\n',
                "\n",
                "      return batch\n",
                "\n",
                "\n",
                "    tokenized_datasets = raw_datasets.map(process_data_to_model_inputs,\n",
                "                                          batched=True,\n",
                "                                          batch_size=2048,\n",
                "                                          remove_columns=['translation'])\n",
                "\n",
                "    model = BartForConditionalGeneration.from_pretrained(config['checkpoint'])\n",
                "\n",
                "\n",
                "    model.config.decoder_start_token_id = en_tokenizer.cls_token_id\n",
                "    model.config.eos_token_id = en_tokenizer.sep_token_id\n",
                "    model.config.pad_token_id = en_tokenizer.pad_token_id\n",
                "\n",
                "\n",
                "    data_collator = DataCollatorForSeq2Seq(tokenizer=en_tokenizer, model=model)\n",
                "\n",
                "    args = Seq2SeqTrainingArguments(\n",
                "        output_dir=config['output_dir'],\n",
                "        per_device_train_batch_size=config['batch_size'],\n",
                "        per_device_eval_batch_size=config['batch_size'],\n",
                "        evaluation_strategy=config['evaluation_strategy'],\n",
                "        eval_steps=config['eval_steps'],\n",
                "        learning_rate=float(config['learning_rate']),\n",
                "        warmup_steps=config['warmup_steps'],\n",
                "        label_smoothing_factor=config['label_smoothing_factor'],\n",
                "        weight_decay=config['weight_decay'],\n",
                "        max_grad_norm=config['max_grad_norm'],\n",
                "        num_train_epochs=config['num_train_epochs'],\n",
                "        lr_scheduler_type=config['lr_scheduler_type'],\n",
                "        seed=config['seed'],\n",
                "        fp16=config['fp16'],\n",
                "        save_total_limit=config['save_total_limit'],\n",
                "        save_strategy=config['save_strategy'],\n",
                "        adafactor=config['adafactor'],\n",
                "        predict_with_generate=config['predict_with_generate'],\n",
                "        logging_strategy=config['logging_strategy'],\n",
                "        logging_steps=config['logging_steps']\n",
                "    )\n",
                "\n",
                "\n",
                "    def postprocess_text(preds, labels):\n",
                "        preds = [pred.strip() for pred in preds]\n",
                "        labels = [[label.strip()] for label in labels]\n",
                "\n",
                "        return preds, labels\n",
                "\n",
                "\n",
                "    def compute_metrics(eval_preds):\n",
                "        labels_ids = eval_preds.label_ids\n",
                "        pred_ids = eval_preds.predictions\n",
                "        pred_str = id_tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
                "        labels_ids[labels_ids == -100] = id_tokenizer.pad_token_id\n",
                "        label_str = id_tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
                "\n",
                "        # postprocessing\n",
                "        pred_str, label_str = postprocess_text(pred_str, label_str)\n",
                "\n",
                "        result = metric.compute(predictions=pred_str, references=label_str, lowercase=False)\n",
                '        result = {"bleu": result["score"]}\n',
                "\n",
                "        prediction_lens = [np.count_nonzero(pred != id_tokenizer.pad_token_id) for pred in pred_ids]\n",
                '        result["gen_len"] = np.mean(prediction_lens)\n',
                "        result = {k: round(v, 4) for k, v in result.items()}\n",
                "        return result\n",
                "\n",
                "    trainer = Seq2SeqTrainer(\n",
                "        model=model,\n",
                "        args=args,\n",
                '        train_dataset=tokenized_datasets["train"],\n',
                '        eval_dataset=tokenized_datasets["valid"],\n',
                "        data_collator=data_collator,\n",
                "        tokenizer=en_tokenizer,\n",
                "        compute_metrics=compute_metrics\n",
                "    )\n",
                "\n",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "8ecca9a7-0bd6-4a19-b423-d4b231170746",
            "metadata": {},
            "outputs": [],
            "source": [
                "# freeze all of the layers in the encoder \n",
                "# for param in model.model.encoder.parameters():\n",
                "    # param.requires_grad = False",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "49ae7138-0a95-4e19-b0ec-0bd93abfe4d7",
            "metadata": {},
            "outputs": [],
            "source": [
                "# freeze all of the layers in the decoder \n",
                "# for param in model.model.decoder.parameters():\n",
                "    # param.requires_grad = False",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "c447c88b-89b7-4883-9dfd-a35107af2da3",
            "metadata": {},
            "outputs": [],
            "source": [
                "# freeze the embedding only\n",
                "for param in model.model.encoder.embed_tokens.parameters():\n",
                "     param.requires_grad = False\n",
                "for param in model.model.encoder.embed_positions.parameters():\n",
                "    param.requires_grad = False",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "c193c7a6-6dd1-4176-9b8e-e91df029e57a",
            "metadata": {},
            "outputs": [],
            "source": [
                "# freeze the first n layers in the encoder \n",
                "n = 5\n",
                "for param in model.model.encoder.layers[:n].parameters():\n",
                "    param.requires_grad = False",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "06727096-b860-42d8-9344-dc852fb393a7",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "number of total parameters: 150452224\n",
                        "number of trainable parameters:  87173120\n",
                    ],
                }
            ],
            "source": [
                "# make sure that the number of parameters trained is correct\n",
                'print("number of total parameters:", model.num_parameters())\n',
                'print("number of trainable parameters: ", model.num_parameters(only_trainable=True))',
            ],
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1006fc9e",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "***** Running training *****\n",
                        "  Num examples = 21690\n",
                        "  Num Epochs = 500\n",
                        "  Instantaneous batch size per device = 28\n",
                        "  Total train batch size (w. parallel, distributed & accumulation) = 28\n",
                        "  Gradient Accumulation steps = 1\n",
                        "  Total optimization steps = 387500\n",
                    ],
                },
                {
                    "data": {
                        "text/html": [
                            "\n",
                            "    <div>\n",
                            "      \n",
                            "      <progress value='18876' max='387500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
                            "      [ 18876/387500 1:50:56 < 36:06:44, 2.84 it/s, Epoch 24.35/500]\n",
                            "    </div>\n",
                            '    <table border="1" class="dataframe">\n',
                            "  <thead>\n",
                            '    <tr style="text-align: left;">\n',
                            "      <th>Step</th>\n",
                            "      <th>Training Loss</th>\n",
                            "      <th>Validation Loss</th>\n",
                            "      <th>Bleu</th>\n",
                            "      <th>Gen Len</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <td>500</td>\n",
                            "      <td>8.829200</td>\n",
                            "      <td>7.533245</td>\n",
                            "      <td>0.046200</td>\n",
                            "      <td>19.971800</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>1000</td>\n",
                            "      <td>7.134500</td>\n",
                            "      <td>6.594310</td>\n",
                            "      <td>3.497600</td>\n",
                            "      <td>19.874600</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>1500</td>\n",
                            "      <td>6.196700</td>\n",
                            "      <td>5.651236</td>\n",
                            "      <td>9.727800</td>\n",
                            "      <td>19.947700</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>2000</td>\n",
                            "      <td>5.352700</td>\n",
                            "      <td>5.010205</td>\n",
                            "      <td>13.789100</td>\n",
                            "      <td>19.931500</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>2500</td>\n",
                            "      <td>4.752900</td>\n",
                            "      <td>4.532782</td>\n",
                            "      <td>18.259800</td>\n",
                            "      <td>19.876300</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>3000</td>\n",
                            "      <td>4.330300</td>\n",
                            "      <td>4.191177</td>\n",
                            "      <td>20.838000</td>\n",
                            "      <td>19.874200</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>3500</td>\n",
                            "      <td>3.935500</td>\n",
                            "      <td>3.956630</td>\n",
                            "      <td>22.264500</td>\n",
                            "      <td>19.857600</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>4000</td>\n",
                            "      <td>3.691100</td>\n",
                            "      <td>3.770090</td>\n",
                            "      <td>24.168400</td>\n",
                            "      <td>19.594000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>4500</td>\n",
                            "      <td>3.455100</td>\n",
                            "      <td>3.640134</td>\n",
                            "      <td>24.274600</td>\n",
                            "      <td>19.926900</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>5000</td>\n",
                            "      <td>3.235200</td>\n",
                            "      <td>3.538574</td>\n",
                            "      <td>25.921700</td>\n",
                            "      <td>19.824800</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>5500</td>\n",
                            "      <td>3.118500</td>\n",
                            "      <td>3.481151</td>\n",
                            "      <td>26.906200</td>\n",
                            "      <td>19.888300</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>6000</td>\n",
                            "      <td>2.928100</td>\n",
                            "      <td>3.427663</td>\n",
                            "      <td>27.596200</td>\n",
                            "      <td>19.719800</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>6500</td>\n",
                            "      <td>2.812500</td>\n",
                            "      <td>3.414835</td>\n",
                            "      <td>27.643500</td>\n",
                            "      <td>19.920300</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>7000</td>\n",
                            "      <td>2.745200</td>\n",
                            "      <td>3.371494</td>\n",
                            "      <td>27.461300</td>\n",
                            "      <td>19.921100</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>7500</td>\n",
                            "      <td>2.569600</td>\n",
                            "      <td>3.357692</td>\n",
                            "      <td>28.101500</td>\n",
                            "      <td>19.956400</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>8000</td>\n",
                            "      <td>2.528800</td>\n",
                            "      <td>3.356396</td>\n",
                            "      <td>28.071600</td>\n",
                            "      <td>19.905400</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>8500</td>\n",
                            "      <td>2.447000</td>\n",
                            "      <td>3.337185</td>\n",
                            "      <td>27.714700</td>\n",
                            "      <td>19.977200</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>9000</td>\n",
                            "      <td>2.319100</td>\n",
                            "      <td>3.358171</td>\n",
                            "      <td>28.141600</td>\n",
                            "      <td>19.957200</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>9500</td>\n",
                            "      <td>2.281800</td>\n",
                            "      <td>3.362147</td>\n",
                            "      <td>27.767400</td>\n",
                            "      <td>19.964300</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>10000</td>\n",
                            "      <td>2.227000</td>\n",
                            "      <td>3.353587</td>\n",
                            "      <td>27.858400</td>\n",
                            "      <td>19.886700</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>10500</td>\n",
                            "      <td>2.121000</td>\n",
                            "      <td>3.368475</td>\n",
                            "      <td>28.106900</td>\n",
                            "      <td>19.958100</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>11000</td>\n",
                            "      <td>2.101200</td>\n",
                            "      <td>3.380998</td>\n",
                            "      <td>27.956600</td>\n",
                            "      <td>19.980900</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>11500</td>\n",
                            "      <td>2.039500</td>\n",
                            "      <td>3.378196</td>\n",
                            "      <td>28.080900</td>\n",
                            "      <td>19.990000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>12000</td>\n",
                            "      <td>1.976000</td>\n",
                            "      <td>3.388390</td>\n",
                            "      <td>27.853700</td>\n",
                            "      <td>19.979200</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>12500</td>\n",
                            "      <td>1.953700</td>\n",
                            "      <td>3.395797</td>\n",
                            "      <td>28.065700</td>\n",
                            "      <td>19.964300</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>13000</td>\n",
                            "      <td>1.893600</td>\n",
                            "      <td>3.396047</td>\n",
                            "      <td>28.044200</td>\n",
                            "      <td>19.980100</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>13500</td>\n",
                            "      <td>1.862000</td>\n",
                            "      <td>3.401350</td>\n",
                            "      <td>28.114300</td>\n",
                            "      <td>19.984200</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>14000</td>\n",
                            "      <td>1.847900</td>\n",
                            "      <td>3.417058</td>\n",
                            "      <td>28.033900</td>\n",
                            "      <td>19.995000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>14500</td>\n",
                            "      <td>1.787400</td>\n",
                            "      <td>3.420749</td>\n",
                            "      <td>28.177600</td>\n",
                            "      <td>19.998800</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>15000</td>\n",
                            "      <td>1.769100</td>\n",
                            "      <td>3.426630</td>\n",
                            "      <td>28.339200</td>\n",
                            "      <td>19.985900</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>15500</td>\n",
                            "      <td>1.761900</td>\n",
                            "      <td>3.434186</td>\n",
                            "      <td>27.705100</td>\n",
                            "      <td>19.994200</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>16000</td>\n",
                            "      <td>1.707600</td>\n",
                            "      <td>3.447206</td>\n",
                            "      <td>28.276300</td>\n",
                            "      <td>19.966800</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>16500</td>\n",
                            "      <td>1.703400</td>\n",
                            "      <td>3.445013</td>\n",
                            "      <td>27.826200</td>\n",
                            "      <td>19.993400</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>17000</td>\n",
                            "      <td>1.686500</td>\n",
                            "      <td>3.461697</td>\n",
                            "      <td>27.637400</td>\n",
                            "      <td>19.995000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>17500</td>\n",
                            "      <td>1.655400</td>\n",
                            "      <td>3.454730</td>\n",
                            "      <td>27.922700</td>\n",
                            "      <td>19.991300</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>18000</td>\n",
                            "      <td>1.650000</td>\n",
                            "      <td>3.468778</td>\n",
                            "      <td>27.989600</td>\n",
                            "      <td>19.988800</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>18500</td>\n",
                            "      <td>1.635000</td>\n",
                            "      <td>3.454805</td>\n",
                            "      <td>28.019500</td>\n",
                            "      <td>19.997500</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table><p>",
                        ],
                        "text/plain": ["<IPython.core.display.HTML object>"],
                    },
                    "metadata": {},
                    "output_type": "display_data",
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "***** Running Evaluation *****\n",
                        "  Num examples = 2409\n",
                        "  Batch size = 28\n",
                        "Saving model checkpoint to bart_en_id_es/checkpoint-500\n",
                        "Configuration saved in bart_en_id_es/checkpoint-500/config.json\n",
                        "Model weights saved in bart_en_id_es/checkpoint-500/pytorch_model.bin\n",
                        "tokenizer config file saved in bart_en_id_es/checkpoint-500/tokenizer_config.json\n",
                        "Special tokens file saved in bart_en_id_es/checkpoint-500/special_tokens_map.json\n",
                        "Deleting older checkpoint [bart_en_id_es/checkpoint-5000] due to args.save_total_limit\n",
                        "***** Running Evaluation *****\n",
                        "  Num examples = 2409\n",
                        "  Batch size = 28\n",
                        "Saving model checkpoint to bart_en_id_es/checkpoint-1000\n",
                        "Configuration saved in bart_en_id_es/checkpoint-1000/config.json\n",
                        "Model weights saved in bart_en_id_es/checkpoint-1000/pytorch_model.bin\n",
                        "tokenizer config file saved in bart_en_id_es/checkpoint-1000/tokenizer_config.json\n",
                        "Special tokens file saved in bart_en_id_es/checkpoint-1000/special_tokens_map.json\n",
                        "Deleting older checkpoint [bart_en_id_es/checkpoint-5500] due to args.save_total_limit\n",
                        "***** Running Evaluation *****\n",
                        "  Num examples = 2409\n",
                        "  Batch size = 28\n",
                        "Saving model checkpoint to bart_en_id_es/checkpoint-1500\n",
                        "Configuration saved in bart_en_id_es/checkpoint-1500/config.json\n",
                        "Model weights saved in bart_en_id_es/checkpoint-1500/pytorch_model.bin\n",
                        "tokenizer config file saved in bart_en_id_es/checkpoint-1500/tokenizer_config.json\n",
                        "Special tokens file saved in bart_en_id_es/checkpoint-1500/special_tokens_map.json\n",
                        "Deleting older checkpoint [bart_en_id_es/checkpoint-6000] due to args.save_total_limit\n",
                        "***** Running Evaluation *****\n",
                        "  Num examples = 2409\n",
                        "  Batch size = 28\n",
                        "Saving model checkpoint to bart_en_id_es/checkpoint-2000\n",
                        "Configuration saved in bart_en_id_es/checkpoint-2000/config.json\n",
                        "Model weights saved in bart_en_id_es/checkpoint-2000/pytorch_model.bin\n",
                        "tokenizer config file saved in bart_en_id_es/checkpoint-2000/tokenizer_config.json\n",
                        "Special tokens file saved in bart_en_id_es/checkpoint-2000/special_tokens_map.json\n",
                        "Deleting older checkpoint [bart_en_id_es/checkpoint-6500] due to args.save_total_limit\n",
                        "***** Running Evaluation *****\n",
                        "  Num examples = 2409\n",
                        "  Batch size = 28\n",
                        "Saving model checkpoint to bart_en_id_es/checkpoint-2500\n",
                        "Configuration saved in bart_en_id_es/checkpoint-2500/config.json\n",
                        "Model weights saved in bart_en_id_es/checkpoint-2500/pytorch_model.bin\n",
                        "tokenizer config file saved in bart_en_id_es/checkpoint-2500/tokenizer_config.json\n",
                        "Special tokens file saved in bart_en_id_es/checkpoint-2500/special_tokens_map.json\n",
                        "Deleting older checkpoint [bart_en_id_es/checkpoint-7000] due to args.save_total_limit\n",
                        "***** Running Evaluation *****\n",
                        "  Num examples = 2409\n",
                        "  Batch size = 28\n",
                        "Saving model checkpoint to bart_en_id_es/checkpoint-3000\n",
                        "Configuration saved in bart_en_id_es/checkpoint-3000/config.json\n",
                        "Model weights saved in bart_en_id_es/checkpoint-3000/pytorch_model.bin\n",
                        "tokenizer config file saved in bart_en_id_es/checkpoint-3000/tokenizer_config.json\n",
                        "Special tokens file saved in bart_en_id_es/checkpoint-3000/special_tokens_map.json\n",
                        "Deleting older checkpoint [bart_en_id_es/checkpoint-7500] due to args.save_total_limit\n",
                        "***** Running Evaluation *****\n",
                        "  Num examples = 2409\n",
                        "  Batch size = 28\n",
                        "Saving model checkpoint to bart_en_id_es/checkpoint-3500\n",
                        "Configuration saved in bart_en_id_es/checkpoint-3500/config.json\n",
                        "Model weights saved in bart_en_id_es/checkpoint-3500/pytorch_model.bin\n",
                        "tokenizer config file saved in bart_en_id_es/checkpoint-3500/tokenizer_config.json\n",
                        "Special tokens file saved in bart_en_id_es/checkpoint-3500/special_tokens_map.json\n",
                        "Deleting older checkpoint [bart_en_id_es/checkpoint-8000] due to args.save_total_limit\n",
                        "***** Running Evaluation *****\n",
                        "  Num examples = 2409\n",
                        "  Batch size = 28\n",
                        "Saving model checkpoint to bart_en_id_es/checkpoint-4000\n",
                        "Configuration saved in bart_en_id_es/checkpoint-4000/config.json\n",
                        "Model weights saved in bart_en_id_es/checkpoint-4000/pytorch_model.bin\n",
                        "tokenizer config file saved in bart_en_id_es/checkpoint-4000/tokenizer_config.json\n",
                        "Special tokens file saved in bart_en_id_es/checkpoint-4000/special_tokens_map.json\n",
                        "Deleting older checkpoint [bart_en_id_es/checkpoint-8500] due to args.save_total_limit\n",
                        "***** Running Evaluation *****\n",
                        "  Num examples = 2409\n",
                        "  Batch size = 28\n",
                        "Saving model checkpoint to bart_en_id_es/checkpoint-4500\n",
                        "Configuration saved in bart_en_id_es/checkpoint-4500/config.json\n",
                        "Model weights saved in bart_en_id_es/checkpoint-4500/pytorch_model.bin\n",
                        "tokenizer config file saved in bart_en_id_es/checkpoint-4500/tokenizer_config.json\n",
                        "Special tokens file saved in bart_en_id_es/checkpoint-4500/special_tokens_map.json\n",
                        "Deleting older checkpoint [bart_en_id_es/checkpoint-9000] due to args.save_total_limit\n",
                        "***** Running Evaluation *****\n",
                        "  Num examples = 2409\n",
                        "  Batch size = 28\n",
                        "Saving model checkpoint to bart_en_id_es/checkpoint-5000\n",
                        "Configuration saved in bart_en_id_es/checkpoint-5000/config.json\n",
                        "Model weights saved in bart_en_id_es/checkpoint-5000/pytorch_model.bin\n",
                        "tokenizer config file saved in bart_en_id_es/checkpoint-5000/tokenizer_config.json\n",
                        "Special tokens file saved in bart_en_id_es/checkpoint-5000/special_tokens_map.json\n",
                        "Deleting older checkpoint [bart_en_id_es/checkpoint-9500] due to args.save_total_limit\n",
                        "***** Running Evaluation *****\n",
                        "  Num examples = 2409\n",
                        "  Batch size = 28\n",
                        "Saving model checkpoint to bart_en_id_es/checkpoint-5500\n",
                        "Configuration saved in bart_en_id_es/checkpoint-5500/config.json\n",
                        "Model weights saved in bart_en_id_es/checkpoint-5500/pytorch_model.bin\n",
                        "tokenizer config file saved in bart_en_id_es/checkpoint-5500/tokenizer_config.json\n",
                        "Special tokens file saved in bart_en_id_es/checkpoint-5500/special_tokens_map.json\n",
                        "Deleting older checkpoint [bart_en_id_es/checkpoint-500] due to args.save_total_limit\n",
                        "***** Running Evaluation *****\n",
                        "  Num examples = 2409\n",
                        "  Batch size = 28\n",
                        "Saving model checkpoint to bart_en_id_es/checkpoint-6000\n",
                        "Configuration saved in bart_en_id_es/checkpoint-6000/config.json\n",
                        "Model weights saved in bart_en_id_es/checkpoint-6000/pytorch_model.bin\n",
                        "tokenizer config file saved in bart_en_id_es/checkpoint-6000/tokenizer_config.json\n",
                        "Special tokens file saved in bart_en_id_es/checkpoint-6000/special_tokens_map.json\n",
                        "Deleting older checkpoint [bart_en_id_es/checkpoint-1000] due to args.save_total_limit\n",
                        "***** Running Evaluation *****\n",
                        "  Num examples = 2409\n",
                        "  Batch size = 28\n",
                        "Saving model checkpoint to bart_en_id_es/checkpoint-6500\n",
                        "Configuration saved in bart_en_id_es/checkpoint-6500/config.json\n",
                        "Model weights saved in bart_en_id_es/checkpoint-6500/pytorch_model.bin\n",
                        "tokenizer config file saved in bart_en_id_es/checkpoint-6500/tokenizer_config.json\n",
                        "Special tokens file saved in bart_en_id_es/checkpoint-6500/special_tokens_map.json\n",
                        "Deleting older checkpoint [bart_en_id_es/checkpoint-1500] due to args.save_total_limit\n",
                        "***** Running Evaluation *****\n",
                        "  Num examples = 2409\n",
                        "  Batch size = 28\n",
                        "Saving model checkpoint to bart_en_id_es/checkpoint-7000\n",
                        "Configuration saved in bart_en_id_es/checkpoint-7000/config.json\n",
                        "Model weights saved in bart_en_id_es/checkpoint-7000/pytorch_model.bin\n",
                        "tokenizer config file saved in bart_en_id_es/checkpoint-7000/tokenizer_config.json\n",
                        "Special tokens file saved in bart_en_id_es/checkpoint-7000/special_tokens_map.json\n",
                        "Deleting older checkpoint [bart_en_id_es/checkpoint-2000] due to args.save_total_limit\n",
                        "***** Running Evaluation *****\n",
                        "  Num examples = 2409\n",
                        "  Batch size = 28\n",
                        "Saving model checkpoint to bart_en_id_es/checkpoint-7500\n",
                        "Configuration saved in bart_en_id_es/checkpoint-7500/config.json\n",
                        "Model weights saved in bart_en_id_es/checkpoint-7500/pytorch_model.bin\n",
                        "tokenizer config file saved in bart_en_id_es/checkpoint-7500/tokenizer_config.json\n",
                        "Special tokens file saved in bart_en_id_es/checkpoint-7500/special_tokens_map.json\n",
                        "Deleting older checkpoint [bart_en_id_es/checkpoint-2500] due to args.save_total_limit\n",
                        "***** Running Evaluation *****\n",
                        "  Num examples = 2409\n",
                        "  Batch size = 28\n",
                        "Saving model checkpoint to bart_en_id_es/checkpoint-8000\n",
                        "Configuration saved in bart_en_id_es/checkpoint-8000/config.json\n",
                        "Model weights saved in bart_en_id_es/checkpoint-8000/pytorch_model.bin\n",
                        "tokenizer config file saved in bart_en_id_es/checkpoint-8000/tokenizer_config.json\n",
                        "Special tokens file saved in bart_en_id_es/checkpoint-8000/special_tokens_map.json\n",
                        "Deleting older checkpoint [bart_en_id_es/checkpoint-3000] due to args.save_total_limit\n",
                        "***** Running Evaluation *****\n",
                        "  Num examples = 2409\n",
                        "  Batch size = 28\n",
                        "Saving model checkpoint to bart_en_id_es/checkpoint-8500\n",
                        "Configuration saved in bart_en_id_es/checkpoint-8500/config.json\n",
                        "Model weights saved in bart_en_id_es/checkpoint-8500/pytorch_model.bin\n",
                        "tokenizer config file saved in bart_en_id_es/checkpoint-8500/tokenizer_config.json\n",
                        "Special tokens file saved in bart_en_id_es/checkpoint-8500/special_tokens_map.json\n",
                        "Deleting older checkpoint [bart_en_id_es/checkpoint-3500] due to args.save_total_limit\n",
                        "***** Running Evaluation *****\n",
                        "  Num examples = 2409\n",
                        "  Batch size = 28\n",
                        "Saving model checkpoint to bart_en_id_es/checkpoint-9000\n",
                        "Configuration saved in bart_en_id_es/checkpoint-9000/config.json\n",
                        "Model weights saved in bart_en_id_es/checkpoint-9000/pytorch_model.bin\n",
                        "tokenizer config file saved in bart_en_id_es/checkpoint-9000/tokenizer_config.json\n",
                        "Special tokens file saved in bart_en_id_es/checkpoint-9000/special_tokens_map.json\n",
                        "Deleting older checkpoint [bart_en_id_es/checkpoint-4000] due to args.save_total_limit\n",
                        "***** Running Evaluation *****\n",
                        "  Num examples = 2409\n",
                        "  Batch size = 28\n",
                        "Saving model checkpoint to bart_en_id_es/checkpoint-9500\n",
                        "Configuration saved in bart_en_id_es/checkpoint-9500/config.json\n",
                        "Model weights saved in bart_en_id_es/checkpoint-9500/pytorch_model.bin\n",
                        "tokenizer config file saved in bart_en_id_es/checkpoint-9500/tokenizer_config.json\n",
                        "Special tokens file saved in bart_en_id_es/checkpoint-9500/special_tokens_map.json\n",
                        "Deleting older checkpoint [bart_en_id_es/checkpoint-4500] due to args.save_total_limit\n",
                        "***** Running Evaluation *****\n",
                        "  Num examples = 2409\n",
                        "  Batch size = 28\n",
                        "Saving model checkpoint to bart_en_id_es/checkpoint-10000\n",
                        "Configuration saved in bart_en_id_es/checkpoint-10000/config.json\n",
                        "Model weights saved in bart_en_id_es/checkpoint-10000/pytorch_model.bin\n",
                        "tokenizer config file saved in bart_en_id_es/checkpoint-10000/tokenizer_config.json\n",
                        "Special tokens file saved in bart_en_id_es/checkpoint-10000/special_tokens_map.json\n",
                        "Deleting older checkpoint [bart_en_id_es/checkpoint-5000] due to args.save_total_limit\n",
                        "***** Running Evaluation *****\n",
                        "  Num examples = 2409\n",
                        "  Batch size = 28\n",
                        "Saving model checkpoint to bart_en_id_es/checkpoint-10500\n",
                        "Configuration saved in bart_en_id_es/checkpoint-10500/config.json\n",
                        "Model weights saved in bart_en_id_es/checkpoint-10500/pytorch_model.bin\n",
                        "tokenizer config file saved in bart_en_id_es/checkpoint-10500/tokenizer_config.json\n",
                        "Special tokens file saved in bart_en_id_es/checkpoint-10500/special_tokens_map.json\n",
                        "Deleting older checkpoint [bart_en_id_es/checkpoint-5500] due to args.save_total_limit\n",
                        "***** Running Evaluation *****\n",
                        "  Num examples = 2409\n",
                        "  Batch size = 28\n",
                        "Saving model checkpoint to bart_en_id_es/checkpoint-11000\n",
                        "Configuration saved in bart_en_id_es/checkpoint-11000/config.json\n",
                        "Model weights saved in bart_en_id_es/checkpoint-11000/pytorch_model.bin\n",
                        "tokenizer config file saved in bart_en_id_es/checkpoint-11000/tokenizer_config.json\n",
                        "Special tokens file saved in bart_en_id_es/checkpoint-11000/special_tokens_map.json\n",
                        "Deleting older checkpoint [bart_en_id_es/checkpoint-6000] due to args.save_total_limit\n",
                        "***** Running Evaluation *****\n",
                        "  Num examples = 2409\n",
                        "  Batch size = 28\n",
                        "Saving model checkpoint to bart_en_id_es/checkpoint-11500\n",
                        "Configuration saved in bart_en_id_es/checkpoint-11500/config.json\n",
                        "Model weights saved in bart_en_id_es/checkpoint-11500/pytorch_model.bin\n",
                        "tokenizer config file saved in bart_en_id_es/checkpoint-11500/tokenizer_config.json\n",
                        "Special tokens file saved in bart_en_id_es/checkpoint-11500/special_tokens_map.json\n",
                        "Deleting older checkpoint [bart_en_id_es/checkpoint-6500] due to args.save_total_limit\n",
                        "***** Running Evaluation *****\n",
                        "  Num examples = 2409\n",
                        "  Batch size = 28\n",
                        "Saving model checkpoint to bart_en_id_es/checkpoint-12000\n",
                        "Configuration saved in bart_en_id_es/checkpoint-12000/config.json\n",
                        "Model weights saved in bart_en_id_es/checkpoint-12000/pytorch_model.bin\n",
                        "tokenizer config file saved in bart_en_id_es/checkpoint-12000/tokenizer_config.json\n",
                        "Special tokens file saved in bart_en_id_es/checkpoint-12000/special_tokens_map.json\n",
                        "Deleting older checkpoint [bart_en_id_es/checkpoint-7000] due to args.save_total_limit\n",
                        "***** Running Evaluation *****\n",
                        "  Num examples = 2409\n",
                        "  Batch size = 28\n",
                        "Saving model checkpoint to bart_en_id_es/checkpoint-12500\n",
                        "Configuration saved in bart_en_id_es/checkpoint-12500/config.json\n",
                        "Model weights saved in bart_en_id_es/checkpoint-12500/pytorch_model.bin\n",
                        "tokenizer config file saved in bart_en_id_es/checkpoint-12500/tokenizer_config.json\n",
                        "Special tokens file saved in bart_en_id_es/checkpoint-12500/special_tokens_map.json\n",
                        "Deleting older checkpoint [bart_en_id_es/checkpoint-7500] due to args.save_total_limit\n",
                        "***** Running Evaluation *****\n",
                        "  Num examples = 2409\n",
                        "  Batch size = 28\n",
                        "Saving model checkpoint to bart_en_id_es/checkpoint-13000\n",
                        "Configuration saved in bart_en_id_es/checkpoint-13000/config.json\n",
                        "Model weights saved in bart_en_id_es/checkpoint-13000/pytorch_model.bin\n",
                        "tokenizer config file saved in bart_en_id_es/checkpoint-13000/tokenizer_config.json\n",
                        "Special tokens file saved in bart_en_id_es/checkpoint-13000/special_tokens_map.json\n",
                        "Deleting older checkpoint [bart_en_id_es/checkpoint-8000] due to args.save_total_limit\n",
                        "***** Running Evaluation *****\n",
                        "  Num examples = 2409\n",
                        "  Batch size = 28\n",
                        "Saving model checkpoint to bart_en_id_es/checkpoint-13500\n",
                        "Configuration saved in bart_en_id_es/checkpoint-13500/config.json\n",
                        "Model weights saved in bart_en_id_es/checkpoint-13500/pytorch_model.bin\n",
                        "tokenizer config file saved in bart_en_id_es/checkpoint-13500/tokenizer_config.json\n",
                        "Special tokens file saved in bart_en_id_es/checkpoint-13500/special_tokens_map.json\n",
                        "Deleting older checkpoint [bart_en_id_es/checkpoint-8500] due to args.save_total_limit\n",
                        "***** Running Evaluation *****\n",
                        "  Num examples = 2409\n",
                        "  Batch size = 28\n",
                        "Saving model checkpoint to bart_en_id_es/checkpoint-14000\n",
                        "Configuration saved in bart_en_id_es/checkpoint-14000/config.json\n",
                        "Model weights saved in bart_en_id_es/checkpoint-14000/pytorch_model.bin\n",
                        "tokenizer config file saved in bart_en_id_es/checkpoint-14000/tokenizer_config.json\n",
                        "Special tokens file saved in bart_en_id_es/checkpoint-14000/special_tokens_map.json\n",
                        "Deleting older checkpoint [bart_en_id_es/checkpoint-9000] due to args.save_total_limit\n",
                        "***** Running Evaluation *****\n",
                        "  Num examples = 2409\n",
                        "  Batch size = 28\n",
                        "Saving model checkpoint to bart_en_id_es/checkpoint-14500\n",
                        "Configuration saved in bart_en_id_es/checkpoint-14500/config.json\n",
                        "Model weights saved in bart_en_id_es/checkpoint-14500/pytorch_model.bin\n",
                        "tokenizer config file saved in bart_en_id_es/checkpoint-14500/tokenizer_config.json\n",
                        "Special tokens file saved in bart_en_id_es/checkpoint-14500/special_tokens_map.json\n",
                        "Deleting older checkpoint [bart_en_id_es/checkpoint-9500] due to args.save_total_limit\n",
                        "***** Running Evaluation *****\n",
                        "  Num examples = 2409\n",
                        "  Batch size = 28\n",
                        "Saving model checkpoint to bart_en_id_es/checkpoint-15000\n",
                        "Configuration saved in bart_en_id_es/checkpoint-15000/config.json\n",
                        "Model weights saved in bart_en_id_es/checkpoint-15000/pytorch_model.bin\n",
                        "tokenizer config file saved in bart_en_id_es/checkpoint-15000/tokenizer_config.json\n",
                        "Special tokens file saved in bart_en_id_es/checkpoint-15000/special_tokens_map.json\n",
                        "Deleting older checkpoint [bart_en_id_es/checkpoint-10000] due to args.save_total_limit\n",
                        "***** Running Evaluation *****\n",
                        "  Num examples = 2409\n",
                        "  Batch size = 28\n",
                        "Saving model checkpoint to bart_en_id_es/checkpoint-15500\n",
                        "Configuration saved in bart_en_id_es/checkpoint-15500/config.json\n",
                        "Model weights saved in bart_en_id_es/checkpoint-15500/pytorch_model.bin\n",
                        "tokenizer config file saved in bart_en_id_es/checkpoint-15500/tokenizer_config.json\n",
                        "Special tokens file saved in bart_en_id_es/checkpoint-15500/special_tokens_map.json\n",
                        "Deleting older checkpoint [bart_en_id_es/checkpoint-10500] due to args.save_total_limit\n",
                        "***** Running Evaluation *****\n",
                        "  Num examples = 2409\n",
                        "  Batch size = 28\n",
                        "Saving model checkpoint to bart_en_id_es/checkpoint-16000\n",
                        "Configuration saved in bart_en_id_es/checkpoint-16000/config.json\n",
                        "Model weights saved in bart_en_id_es/checkpoint-16000/pytorch_model.bin\n",
                        "tokenizer config file saved in bart_en_id_es/checkpoint-16000/tokenizer_config.json\n",
                        "Special tokens file saved in bart_en_id_es/checkpoint-16000/special_tokens_map.json\n",
                        "Deleting older checkpoint [bart_en_id_es/checkpoint-11000] due to args.save_total_limit\n",
                        "***** Running Evaluation *****\n",
                        "  Num examples = 2409\n",
                        "  Batch size = 28\n",
                        "Saving model checkpoint to bart_en_id_es/checkpoint-16500\n",
                        "Configuration saved in bart_en_id_es/checkpoint-16500/config.json\n",
                        "Model weights saved in bart_en_id_es/checkpoint-16500/pytorch_model.bin\n",
                        "tokenizer config file saved in bart_en_id_es/checkpoint-16500/tokenizer_config.json\n",
                        "Special tokens file saved in bart_en_id_es/checkpoint-16500/special_tokens_map.json\n",
                        "Deleting older checkpoint [bart_en_id_es/checkpoint-11500] due to args.save_total_limit\n",
                        "***** Running Evaluation *****\n",
                        "  Num examples = 2409\n",
                        "  Batch size = 28\n",
                        "Saving model checkpoint to bart_en_id_es/checkpoint-17000\n",
                        "Configuration saved in bart_en_id_es/checkpoint-17000/config.json\n",
                        "Model weights saved in bart_en_id_es/checkpoint-17000/pytorch_model.bin\n",
                        "tokenizer config file saved in bart_en_id_es/checkpoint-17000/tokenizer_config.json\n",
                        "Special tokens file saved in bart_en_id_es/checkpoint-17000/special_tokens_map.json\n",
                        "Deleting older checkpoint [bart_en_id_es/checkpoint-12000] due to args.save_total_limit\n",
                        "***** Running Evaluation *****\n",
                        "  Num examples = 2409\n",
                        "  Batch size = 28\n",
                        "Saving model checkpoint to bart_en_id_es/checkpoint-17500\n",
                        "Configuration saved in bart_en_id_es/checkpoint-17500/config.json\n",
                        "Model weights saved in bart_en_id_es/checkpoint-17500/pytorch_model.bin\n",
                        "tokenizer config file saved in bart_en_id_es/checkpoint-17500/tokenizer_config.json\n",
                        "Special tokens file saved in bart_en_id_es/checkpoint-17500/special_tokens_map.json\n",
                        "Deleting older checkpoint [bart_en_id_es/checkpoint-12500] due to args.save_total_limit\n",
                        "***** Running Evaluation *****\n",
                        "  Num examples = 2409\n",
                        "  Batch size = 28\n",
                        "Saving model checkpoint to bart_en_id_es/checkpoint-18000\n",
                        "Configuration saved in bart_en_id_es/checkpoint-18000/config.json\n",
                        "Model weights saved in bart_en_id_es/checkpoint-18000/pytorch_model.bin\n",
                        "tokenizer config file saved in bart_en_id_es/checkpoint-18000/tokenizer_config.json\n",
                        "Special tokens file saved in bart_en_id_es/checkpoint-18000/special_tokens_map.json\n",
                        "Deleting older checkpoint [bart_en_id_es/checkpoint-13000] due to args.save_total_limit\n",
                        "***** Running Evaluation *****\n",
                        "  Num examples = 2409\n",
                        "  Batch size = 28\n",
                        "Saving model checkpoint to bart_en_id_es/checkpoint-18500\n",
                        "Configuration saved in bart_en_id_es/checkpoint-18500/config.json\n",
                        "Model weights saved in bart_en_id_es/checkpoint-18500/pytorch_model.bin\n",
                        "tokenizer config file saved in bart_en_id_es/checkpoint-18500/tokenizer_config.json\n",
                        "Special tokens file saved in bart_en_id_es/checkpoint-18500/special_tokens_map.json\n",
                        "Deleting older checkpoint [bart_en_id_es/checkpoint-13500] due to args.save_total_limit\n",
                    ],
                },
            ],
            "source": ["trainer.train()"],
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6957986b-3262-46ec-9370-4624709e3191",
            "metadata": {},
            "outputs": [],
            "source": [],
        },
    ],
    "metadata": {
        "jupytext": {
            "cell_metadata_filter": "-all",
            "main_language": "python",
            "notebook_metadata_filter": "-all",
        },
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3",
        },
        "language_info": {
            "codemirror_mode": {"name": "ipython", "version": 3},
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10",
        },
    },
    "nbformat": 4,
    "nbformat_minor": 5,
}
